#!/usr/bin/env node

/**
 * Script para fazer backup completo da base de dados Supabase
 * 
 * Este script:
 * 1. Conecta Ã  base de dados remota
 * 2. Exporta todas as tabelas
 * 3. Inclui estrutura (DDL) e dados (DML)
 * 4. Gera um ficheiro timestamped
 * 5. Salva no diretÃ³rio archive/sql/
 */

import { exec } from 'child_process';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

// Obter __dirname em ES modules
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// ConfiguraÃ§Ãµes da base de dados
const DB_CONFIG = {
  host: 'db.ebitcwrrcumsvqjgrapw.supabase.co',
  port: 5432,
  database: 'postgres',
  user: 'postgres',
  password: '!CapitaoMat14',
  projectId: 'ebitcwrrcumsvqjgrapw'
};

// FunÃ§Ã£o para gerar timestamp
function getTimestamp() {
  const now = new Date();
  return now.toISOString().replace(/[:.]/g, '-').slice(0, 19);
}

// FunÃ§Ã£o para criar backup
async function createBackup() {
  const timestamp = getTimestamp();
  const backupDir = path.join(__dirname, '..', 'archive', 'sql');
  const backupFile = path.join(backupDir, `backup_completo_${timestamp}.sql`);
  
  // Garantir que o diretÃ³rio existe
  if (!fs.existsSync(backupDir)) {
    fs.mkdirSync(backupDir, { recursive: true });
  }

  // Comando pg_dump
  const pgDumpCommand = `pg_dump --host=${DB_CONFIG.host} --port=${DB_CONFIG.port} --username=${DB_CONFIG.user} --dbname=${DB_CONFIG.database} --verbose --clean --no-owner --no-privileges --schema=public --file="${backupFile}"`;

  console.log('ğŸ”„ Iniciando backup da base de dados...');
  console.log(`ğŸ“ Ficheiro de destino: ${backupFile}`);
  console.log(`â° Timestamp: ${timestamp}`);
  console.log('');

  // Definir variÃ¡vel de ambiente para a password
  const env = { ...process.env, PGPASSWORD: DB_CONFIG.password };

  return new Promise((resolve, reject) => {
    const child = exec(pgDumpCommand, { env }, (error, stdout, stderr) => {
      if (error) {
        console.error('âŒ Erro durante o backup:', error.message);
        console.error('stderr:', stderr);
        reject(error);
        return;
      }

      if (stderr) {
        console.log('âš ï¸ Avisos durante o backup:', stderr);
      }

      console.log('âœ… Backup concluÃ­do com sucesso!');
      console.log(`ğŸ“„ Ficheiro criado: ${backupFile}`);
      
      // Verificar tamanho do ficheiro
      try {
        const stats = fs.statSync(backupFile);
        const fileSizeInMB = (stats.size / (1024 * 1024)).toFixed(2);
        console.log(`ğŸ“Š Tamanho do ficheiro: ${fileSizeInMB} MB`);
      } catch (err) {
        console.log('âš ï¸ NÃ£o foi possÃ­vel verificar o tamanho do ficheiro');
      }

      resolve(backupFile);
    });

    // Mostrar progresso em tempo real
    child.stdout?.on('data', (data) => {
      console.log('ğŸ“¤', data.toString().trim());
    });

    child.stderr?.on('data', (data) => {
      console.log('ğŸ“¥', data.toString().trim());
    });
  });
}

// FunÃ§Ã£o para criar backup apenas da estrutura (sem dados)
async function createStructureBackup() {
  const timestamp = getTimestamp();
  const backupDir = path.join(__dirname, '..', 'archive', 'sql');
  const backupFile = path.join(backupDir, `estrutura_${timestamp}.sql`);
  
  if (!fs.existsSync(backupDir)) {
    fs.mkdirSync(backupDir, { recursive: true });
  }

  const pgDumpCommand = `pg_dump --host=${DB_CONFIG.host} --port=${DB_CONFIG.port} --username=${DB_CONFIG.user} --dbname=${DB_CONFIG.database} --verbose --clean --no-owner --no-privileges --schema=public --schema-only --file="${backupFile}"`;

  console.log('ğŸ”„ Criando backup da estrutura...');
  console.log(`ğŸ“ Ficheiro: ${backupFile}`);

  const env = { ...process.env, PGPASSWORD: DB_CONFIG.password };

  return new Promise((resolve, reject) => {
    exec(pgDumpCommand, { env }, (error, stdout, stderr) => {
      if (error) {
        console.error('âŒ Erro:', error.message);
        reject(error);
        return;
      }

      console.log('âœ… Estrutura exportada com sucesso!');
      resolve(backupFile);
    });
  });
}

// FunÃ§Ã£o para criar backup apenas dos dados (sem estrutura)
async function createDataBackup() {
  const timestamp = getTimestamp();
  const backupDir = path.join(__dirname, '..', 'archive', 'sql');
  const backupFile = path.join(backupDir, `dados_${timestamp}.sql`);
  
  if (!fs.existsSync(backupDir)) {
    fs.mkdirSync(backupDir, { recursive: true });
  }

  const pgDumpCommand = `pg_dump --host=${DB_CONFIG.host} --port=${DB_CONFIG.port} --username=${DB_CONFIG.user} --dbname=${DB_CONFIG.database} --verbose --clean --no-owner --no-privileges --schema=public --data-only --file="${backupFile}"`;

  console.log('ğŸ”„ Criando backup dos dados...');
  console.log(`ğŸ“ Ficheiro: ${backupFile}`);

  const env = { ...process.env, PGPASSWORD: DB_CONFIG.password };

  return new Promise((resolve, reject) => {
    exec(pgDumpCommand, { env }, (error, stdout, stderr) => {
      if (error) {
        console.error('âŒ Erro:', error.message);
        reject(error);
        return;
      }

      console.log('âœ… Dados exportados com sucesso!');
      resolve(backupFile);
    });
  });
}

// FunÃ§Ã£o principal
async function main() {
  const args = process.argv.slice(2);
  const type = args[0] || 'full';

  try {
    console.log('ğŸš€ Iniciando processo de backup...');
    console.log(`ğŸ“‹ Tipo de backup: ${type}`);
    console.log('');

    switch (type) {
      case 'structure':
        await createStructureBackup();
        break;
      case 'data':
        await createDataBackup();
        break;
      case 'full':
      default:
        await createBackup();
        break;
    }

    console.log('');
    console.log('ğŸ‰ Processo de backup concluÃ­do!');
    console.log('ğŸ“‚ Verifique os ficheiros em: archive/sql/');

  } catch (error) {
    console.error('ğŸ’¥ Erro fatal:', error.message);
    process.exit(1);
  }
}

// Executar se chamado diretamente
if (import.meta.url === `file://${process.argv[1]}`) {
  main();
}

export {
  createBackup,
  createStructureBackup,
  createDataBackup
}; 